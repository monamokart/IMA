{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TdpPHz2Lp6VD"
   },
   "source": [
    "# TP Coding an autoencoder in tensorflow/keras\n",
    "\n",
    "Author : Alasdair Newson\n",
    "\n",
    "alasdair.newson@telecom-paris.fr\n",
    "\n",
    "## Objective:\n",
    "\n",
    "The goal of this TP is to explore autoencoders and variational autoencoders applied to a simple dataset. In this first part, we will look at an autoencoder applied to MNIST.\n",
    "\n",
    "### Your task:\n",
    "You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE or # FILL IN CODE)\n",
    "\n",
    "First of all, let's load some packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JqNeIJ8Op8Ao"
   },
   "outputs": [],
   "source": [
    "\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout, BatchNormalization, Activation, ZeroPadding2D, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hyj5dj_eui9D"
   },
   "source": [
    "First, we define a function to load the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4YPLKlPrufSk"
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "  (X_train, Y_train_scalar), (X_test, Y_test_scalar) = mnist.load_data()\n",
    "\n",
    "  n_max = 10000\n",
    "  X_train = X_train[0:n_max,:,:]\n",
    "  X_test = X_test[0:n_max,:,:]\n",
    "  Y_train_scalar = Y_train_scalar[0:n_max]\n",
    "  Y_test_scalar = Y_test_scalar[0:n_max]\n",
    "\n",
    "  # normalise images between 0 and 1\n",
    "  X_train = X_train/255.0\n",
    "  X_test = X_test/255.0\n",
    "  #add a channel dimension, if need be (for mnist data)\n",
    "  if(X_train.ndim ==3):\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "    X_test = np.expand_dims(X_test, axis=3)\n",
    "  return X_train,X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-bkK4ktwfvC"
   },
   "source": [
    "Now, we define the general parameters of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mD56EDzbvUxq"
   },
   "outputs": [],
   "source": [
    "X_train,X_test = load_data()\n",
    "\n",
    "# autoencoder parameters\n",
    "optimizer = Adam(0.01, 0.5) #\n",
    "img_rows = X_train.shape[1]\n",
    "img_cols = X_train.shape[2]\n",
    "img_channels = X_train.shape[3]\n",
    "img_size = X_train.shape[1] * X_train.shape[2] * X_train.shape[3]\n",
    "img_shape = (img_rows, img_cols, img_channels)\n",
    "z_dim = 10\n",
    "batch_size = 64\n",
    "n_epochs = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jLa2-jQwxSI"
   },
   "source": [
    "Now, define the autoencoder architecture. In the first part, we will use the following MLP architecture :\n",
    "\n",
    "Encoder :\n",
    "- Flatten input\n",
    "- Dense layer, output size z_dim\n",
    "- Leaky ReLU, with $\\alpha=0.2$\n",
    "\n",
    "Decoder :\n",
    "- Dense layer, output size 784\n",
    "- Sigmoid Activation\n",
    "- Reshape, to size $28\\times 28\\times 1$\n",
    "\n",
    "For the Reshape operation, use a ```Reshape``` layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5fKIM5x0pxXR"
   },
   "outputs": [],
   "source": [
    "n_pixels = img_rows*img_cols*img_channels\n",
    "\n",
    "#BEGIN FILL IN CODE\n",
    "#END FILL IN CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-659aM36xvXX"
   },
   "source": [
    "Now, display the model (summary) and compile it. Use the binary cross-entropy loss, since we are in the case of MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfqX6Brlxjyi"
   },
   "outputs": [],
   "source": [
    "# Build and compile the discriminator\n",
    "# BEGIN FILL IN CODE\n",
    "\n",
    "# END FILL IN CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3EbmswSzJdK"
   },
   "source": [
    "We define a function to carry out testing on the autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8jXjdRyzMy2"
   },
   "outputs": [],
   "source": [
    "\t\n",
    "def test_images(ae_model, test_data):\n",
    "  n_images = 5\n",
    "  idx = np.random.randint(0, test_data.shape[0], n_images)\n",
    "  test_imgs = test_data[idx,:,:,:]\n",
    "\n",
    "  #get output images\n",
    "  output_imgs = ae_model.predict( test_imgs )\n",
    "  \n",
    "  r = 2\n",
    "  c = n_images\n",
    "  fig, axs = plt.subplots(r, c)\n",
    "  for j in range(c):\n",
    "    #black and white images\n",
    "    axs[0,j].imshow(test_imgs[j, :,:,0], cmap='gray')\n",
    "    axs[0,j].axis('off')\n",
    "    axs[1,j].imshow(output_imgs[j, :,:,0], cmap='gray')\n",
    "    axs[1,j].axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO9ATQEiyr3b"
   },
   "source": [
    "### Train the model\n",
    "\n",
    "Now, train the model on the mnist dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sUXHCtvW2iQ0"
   },
   "outputs": [],
   "source": [
    "# BEGIN FILL IN CODE\n",
    "\n",
    "# END FILL IN CODE\n",
    "test_images(ae_model, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktuGdSig5qC7"
   },
   "source": [
    "## Convolutional model\n",
    "\n",
    "Now, we are going to implement a convolutional architecture (with two dense layers in the middle) and compare the results. Implement the following architecture :\n",
    "\n",
    "Encoder :\n",
    "- 2D convolution, filter size $3\\times3$, 8 filters, stride=(2,2), padding=\"SAME\"\n",
    "- LeakyReLU ($\\alpha=0.2$)\n",
    "- 2D convolution, filter size $3\\times3$, 4 filters, stride=(2,2), padding=\"SAME\"\n",
    "- LeakyReLU ($\\alpha=0.2$)\n",
    "- Flatten tensor\n",
    "- Dense layer, output size z_dim\n",
    "\n",
    "Decoder :\n",
    "- Dense layer, output size 196\n",
    "- LeakyReLU ($\\alpha=0.2$)\n",
    "- Reshape $(7\\times7\\times 4)$\n",
    "- 2D transposed convolution, filter size $3\\times3$, 8 filters, stride=(2,2), padding=\"SAME\"\n",
    "- LeakyReLU ($\\alpha=0.2$)\n",
    "- 2D transposed convolution, filter size $3\\times3$, 1 filter, stride=(2,2), padding=\"SAME\"\n",
    "- Sigmoid activation\n",
    "\n",
    "The sizes of the tensors in the encoder and the decoder should be :\n",
    "- $28 \\times 28 \\times 1$ -> $14 \\times 14 \\times 8$ -> $7 \\times 7 \\times 4$ -> z_dim\n",
    "- z_dim -> $7 \\times 7 \\times 4$ -> $14 \\times 14 \\times 8$ -> $28 \\times 28 \\times 1$\n",
    "\n",
    "Use the previous code as an example, and implement and train the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWuikdCrvZ1V"
   },
   "outputs": [],
   "source": [
    "\n",
    "#BEGIN FILL IN CODE\n",
    "\n",
    "#END FILL IN CODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WWs6uhIa-hko"
   },
   "source": [
    "Are the performances better with this model ? Compare the number of parameters in the MLP and convolutional case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5TmOfau_dhZ"
   },
   "source": [
    "## Denoising autoencoder\n",
    "\n",
    "In this part, we take the previous architecture, but now we implement a __denoising__ autoencoder. For this, we simply add Gaussian noise to the input during training, and require the autoencoder to reconstruct the non-noisy ground truth. You can do add the noise using the following function :\n",
    "- np.random.normal(loc=0.0, scale=1.0, size=curr_batch.shape)\n",
    "\n",
    "First, we modify the ```test_images``` function to take into account a noisy input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6iYCO0S_5I_"
   },
   "outputs": [],
   "source": [
    "\n",
    "def test_images(ae_model, test_data, sigma):\n",
    "  n_images = 5\n",
    "  idx = np.random.randint(0, test_data.shape[0], n_images)\n",
    "  test_imgs = test_data[idx,:,:,:]\n",
    "\n",
    "  #get output images\n",
    "  test_imgs = np.clip(test_imgs + sigma * np.random.normal(loc=0.0, scale=1.0, size=test_imgs.shape),0.,1.)\n",
    "  output_imgs = ae_model.predict( test_imgs )\n",
    "  \n",
    "  r = 2\n",
    "  c = n_images\n",
    "  fig, axs = plt.subplots(r, c)\n",
    "  for j in range(c):\n",
    "    #black and white images\n",
    "    axs[0,j].imshow(test_imgs[j, :,:,0], cmap='gray')\n",
    "    axs[0,j].axis('off')\n",
    "    axs[1,j].imshow(output_imgs[j, :,:,0], cmap='gray')\n",
    "    axs[1,j].axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbRhMZv6_5y4"
   },
   "source": [
    "Now, use the previous codes to implement the denoising autoencoder. Use either the MLP architecture or the convolutional architecture.\n",
    "\n",
    "__IMPORTANT NOTE__ For this part of the TP, you will have to use a custom training process (to add the noise to a batch). For this, you can use the following function :\n",
    "\n",
    "- loss_value = ae_model.train_on_batch(X,Y)\n",
    "\n",
    "This allows you to create a custom batch. X should be the noisy batch, and Y should be the non-noisy batch\n",
    "\n",
    "In this case, to simplify things, __do not worry about carrying out the complete batch over the database__, simply iterate n_iters times, and select a random batch at each iteration. To select a random set (of size batch_size) of integers between 0 and X_train.shape, use :\n",
    "\n",
    "- np.random.randint(0, X_train.shape[0], batch_size)\n",
    "\n",
    "Use sigma = 25.0/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MUU7ky7D_bV7"
   },
   "outputs": [],
   "source": [
    "\n",
    "sigma = 25.0/255.0\n",
    "n_iters = 1000\n",
    "display_loss_step = 100\n",
    "\n",
    "#BEGIN FILL IN CODE\n",
    "\n",
    "# END FILL IN CODE"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "tp_ima_206_ae_for_students.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
